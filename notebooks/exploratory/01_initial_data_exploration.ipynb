{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Exploration - Seattle Crime Data\n",
    "\n",
    "**Objective**: Load and perform initial exploration of Seattle Police Department crime data\n",
    "\n",
    "**Author**: Seattle Crime Analysis Team  \n",
    "**Date**: 2026-02-06  \n",
    "**Data Source**: [Seattle Open Data Portal - SPD Crime Data](https://data.seattle.gov/Public-Safety/SPD-Crime-Data-2008-Present/tazs-3rd5)\n",
    "\n",
    "## Notebook Outline\n",
    "1. Load and inspect raw data\n",
    "2. Check data types and missing values\n",
    "3. Basic statistical summary\n",
    "4. Temporal analysis (date/time patterns)\n",
    "5. Spatial analysis (coordinate validation)\n",
    "6. Crime type distribution\n",
    "7. Data quality assessment\n",
    "8. Initial findings and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n",
    "\n",
    "Load the Seattle crime data from the raw data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "data_path = Path('../../data/raw/spd_crime_data.csv')\n",
    "\n",
    "# Check if file exists\n",
    "if not data_path.exists():\n",
    "    print(f\"❌ Data file not found at: {data_path}\")\n",
    "    print(\"\\nPlease download the data using one of these methods:\")\n",
    "    print(\"1. Manual: https://data.seattle.gov/Public-Safety/SPD-Crime-Data-2008-Present/tazs-3rd5\")\n",
    "    print(\"2. Script: python scripts/download_data.py\")\n",
    "    print(\"3. API: See SETUP.md for instructions\")\n",
    "else:\n",
    "    print(f\"✅ Data file found at: {data_path}\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    print(f\"✅ Data loaded successfully!\")\n",
    "    print(f\"   Records: {len(df):,}\")\n",
    "    print(f\"   Columns: {len(df.columns)}\")\n",
    "    print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column information\n",
    "print(\"Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names\n",
    "print(\"Column Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percent': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Data_Type': df.dtypes\n",
    "})\n",
    "\n",
    "# Sort by missing percentage\n",
    "missing_stats = missing_stats.sort_values('Missing_Percent', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_stats[missing_stats['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_stats['Missing_Count'].sum() > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    missing_cols = missing_stats[missing_stats['Missing_Count'] > 0]\n",
    "    ax.barh(missing_cols['Column'], missing_cols['Missing_Percent'])\n",
    "    ax.set_xlabel('Missing Percentage (%)')\n",
    "    ax.set_title('Missing Values by Column')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns summary\n",
    "print(\"Categorical Columns Summary:\")\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis\n",
    "\n",
    "Analyze date/time patterns in the crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify date/time columns (adjust based on actual column names)\n",
    "date_columns = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "print(f\"Date/Time columns found: {date_columns}\")\n",
    "\n",
    "# TODO: Parse dates and analyze temporal patterns\n",
    "# Example:\n",
    "# df['offense_start_datetime'] = pd.to_datetime(df['offense_start_datetime'])\n",
    "# df['year'] = df['offense_start_datetime'].dt.year\n",
    "# df['month'] = df['offense_start_datetime'].dt.month\n",
    "# df['day_of_week'] = df['offense_start_datetime'].dt.day_name()\n",
    "# df['hour'] = df['offense_start_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Spatial Analysis\n",
    "\n",
    "Validate and explore geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify coordinate columns\n",
    "coord_columns = [col for col in df.columns if 'lat' in col.lower() or 'lon' in col.lower()]\n",
    "print(f\"Coordinate columns found: {coord_columns}\")\n",
    "\n",
    "# TODO: Validate coordinates and check for outliers\n",
    "# Seattle approximate bounds:\n",
    "# Latitude: 47.4 to 47.8\n",
    "# Longitude: -122.5 to -122.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Crime Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify crime type columns\n",
    "crime_columns = [col for col in df.columns if 'offense' in col.lower() or 'crime' in col.lower()]\n",
    "print(f\"Crime-related columns found: {crime_columns}\")\n",
    "\n",
    "# TODO: Analyze distribution of crime types\n",
    "# Example:\n",
    "# crime_counts = df['offense'].value_counts()\n",
    "# print(crime_counts.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Assessment\n",
    "\n",
    "Document any data quality issues found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "print(\"Data Quality Summary:\")\n",
    "print(f\"\\n1. Total Records: {len(df):,}\")\n",
    "print(f\"2. Duplicate Records: {df.duplicated().sum():,}\")\n",
    "print(f\"3. Columns with Missing Data: {(df.isnull().sum() > 0).sum()}\")\n",
    "print(f\"4. Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# TODO: Add more quality checks based on data characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Initial Findings\n",
    "\n",
    "**Summary of Key Observations:**\n",
    "\n",
    "1. **Data Volume**: [To be completed after analysis]\n",
    "2. **Data Quality**: [To be completed after analysis]\n",
    "3. **Temporal Coverage**: [To be completed after analysis]\n",
    "4. **Spatial Coverage**: [To be completed after analysis]\n",
    "5. **Crime Types**: [To be completed after analysis]\n",
    "\n",
    "**Data Quality Issues Identified:**\n",
    "- [List issues found]\n",
    "\n",
    "**Next Steps:**\n",
    "1. Clean and preprocess data based on findings\n",
    "2. Handle missing values appropriately\n",
    "3. Validate and correct spatial coordinates\n",
    "4. Standardize date/time formats\n",
    "5. Create processed dataset for analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Status**: Template - Ready for data exploration  \n",
    "**Next Notebook**: `02_data_cleaning_preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seattle Crime Analysis",
   "language": "python",
   "name": "seattle-crime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
